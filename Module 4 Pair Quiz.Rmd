---
title: "Module 4 Pair Quiz"
author: "Raphael Lee, Javier Bolong"
date: "7/30/2021"
output: html_document
---

## *Question 1*
<p>&nbsp;</p>
<font size = "3"> An article in the Journal of Sound and Vibration ["Measurement of Noise-Evoked Blood Pressure by Means of Averaging Method: Relation between Blood Pressure Rise and PSL" (1991, Vol. 151(3), pp. 383-394)] described a study investigating the relationship between noise exposure and hypertension. The following data are representative of those reported in the article. </font>
<p>&nbsp;</p>

# **A**
<p>&nbsp;</p>
<font size = "3"> a) Draw a scatter diagram of y (blood pressure rise in millimeters of mercury) versus x (sound pressure level in decibels). Does a simple linear regression model seem reasonable in this situation? </font>
<p>&nbsp;</p>

```{r Q1scatterplot, echo =FALSE}
library(readxl)
testing <- read_excel("testing.xlsx")
x <- testing$x
y <- testing$y
n <- 20
plot(x, y, main = "Scatterplot x and y", xlab = "(x) Sound pressure level in decibels (decibels/dB)", ylab = "(y) Blood pressure (milimeters/mL of mercury)")
```

<p>&nbsp;</p>
  <font size = "3"> The scatter plot was plotted down using the code above. On first glance, if an imaginary line were to be put in the center amidst the points, there would be a fairly good correlation. However to confirm it with numbers, a regression analysis was done. For a regression model to be adequate, a residual analysis must be conducted</font>
<p>&nbsp;</p>
```{r Q1equation, echo=FALSE}
# equation for slope  
m <- ((sum(x * y) - ((sum(x) * sum(y)))/20)) / (sum(x^2) - (((sum(x))^2) / 20))
m
# solving for the set of y-hats
x_bar <- (sum(x)) / 20
y_bar <- (sum(y)) / 20
intercept <- y_bar - (m * x_bar)
intercept
lm(y~x)

```
<p>&nbsp;</p>
  <font size = "3"><center> The code above was used to obtain the equation </font></center>
$$\widehat{y} = `r m`(x) + (`r intercept`)$$
<p>&nbsp;</p>

```{r Q1yhats, echo=TRUE}
# solving for set_residuals
set_y_hats <- (m * x) + intercept

```
<p>&nbsp;</p>

<font size = "3">Then using this equation, using each x-value in the set, we get a y hat value. The code above was used to do that </font>

<p>&nbsp;</p>

```{r Q1residuals, echo=TRUE}
set_residuals <- y -set_y_hats
set_residuals
shapiro.test(set_residuals)
plot(set_y_hats, set_residuals, main = "Fitted Values vs Residuals", xlab = "Fitted Values", ylab = "Residuals")
```
<p>&nbsp;</p>
<font size = "3">Then the set of residuals was made using the code above and a scatter plot. Using the Shapiro Wilk test, the set of residuals is normally distributed since the the p-value is more than 0.05. Based of the scatter plot of fitted values and residuals, the points are random variables  due to its random spread of the graph. The variance is constant since there is a regular thickness in terms of spread as we move left to right. Thus a simple linear regression model is appropriate. Another test can be done using the coefficient of Determination.  </font>
<p>&nbsp;</p>

``` {r Q1 coefficient of determination, echo =TRUE}

k_determination <- (cor(x, y)^2)

k_determination
```


<p>&nbsp;</p>
<font size = "3">The above code was used to find the correlation coefficient. Since squaring that will give the coefficient of determination, the above code was used. </font>
<p>&nbsp;</p>

$$R^2 = 1 - \frac{SS_E}{SS_T} = `r k_determination`$$
<p>&nbsp;</p>

  <font size = "3"> Since the number above is in between 0 and 1 and the value is relatively high, which indicates a strong ability to predict outcomes, we can also conclude that a simple linear regression model can be used. </font>
  
<p>&nbsp;</p>

 <font size = "3"> Answer: Simple linear regression model is suitable for the given situation. </font>
 
<p>&nbsp;</p>
# **B**
<p>&nbsp;</p>
<font size = "3"> b) Fit the simple linear regression model using least squares. Find an estimate of σ2.</font>
<p>&nbsp;</p>

```{r Q2_line, echo =TRUE}
plot(x, y, main = "Scatterplot x and y", xlab = "(x) Sound pressure level in decibels (decibels/dB)", ylab = "(y) Blood pressure (milimeters/mL of mercury)")
abline(lm(y~x), col = "red")

```
<p>&nbsp;</p>
<font size ="3">The above code was used to plot a simple linear regression model. With the function lm, the line was plotted for the scatter plot. </font>
<p>&nbsp;</p>
``` {r Q2_estimator, echo = TRUE}
estimator <- (sum((y - set_y_hats) ^ 2)) / (n - 2)
estimator

```
<p>&nbsp;</p>
<font size ="3">The above code was used to find the unbiased estimator.  </font>
<p>&nbsp;</p>

<font size ="3"> Final answer: </font>
$$UnbiasedEstimator =  `estimator`$$
<p>&nbsp;</p>

# **C**
<p>&nbsp;</p>
<font size = "3"> c) Find the predicted mean rise in blood pressure level associated with a sound pressure level of 85 decibels.</font>
<p>&nbsp;</p>

```{r Q3_Mean, echo = TRUE}
new_y <- (m * 85) + intercept
new_y
```
<p>&nbsp;</p>

<font size = "3"> Using the code above and the equation of the line obtained in a), the value 85 replaced x to get the new observation y.</font>

<p>&nbsp;</p>

<font size = "3"> Using the code above and the equation of the line obtained in a), the value 85 replaced x to get the new observation y.</font>

<p>&nbsp;</p>

<font size = "3">Answer: </font>
$$PredictedMean Rise = (`r m` * 85) + `r intercept` = `r new_y`$$
<p>&nbsp;</p>




## Question 2


<font size="3">An article in Optical Engineering ["Operating Curve Extraction of a Correlator's Filter" (2004, Vol. 43, pp. 2775-2779)] reported on the use of an optical correlator to perform an experiment by varying brightness and contrast. The resulting modulation is characterized by the useful range of gray levels. The data follows:
</font>

## **A.**

<font size="3">

a) Fit a multiple linear regression model to these data.

To help us find the multiple linear regression model, we store the data values in an excel sheet and read them from there. After, we can plot the data points. Using the lm function in R, we can obtain some useful numbers to help find the multiple regression model of our data set.
``` {r question2, echo=TRUE}
library(readxl)
q2 <- read_excel("~/GitHub/Module-4-Pair-Quiz/question2.xls")
plot(q2)

Brightness <- q2$Brightness
Contrast <- q2$Contrast
Useful_Range <-q2$`Useful Range`


multiple_regression <- lm(Useful_Range ~ Brightness + Contrast, data=q2)
summary(multiple_regression)
```


We obtain values such as the Residuals, coefficients, t-values, and residual standard error. We even get the p-value of the whole data set.



From the coefficients above, we can form the multiple linear regression model below



We use: 

$$\hat{y} = Intercept + CoeffBrightness(X_1) + CoeffContrast(X_2)$$

</font>

$$Useful Range = 224.7179 + (0.7768)(X_1) + (-3.2017)(X_2)$$

## **B.**

<font size="3">

b) Estimate $\sigma^2$


We use the formula:
$\sigma^2 = \frac{SSE}{n-(k+1)}$, where k is the number of coefficients

SSE here is obtained from the intercept of Error values from the lm table above.
``` {r studio, echo=FALSE}
sig <- ((50.1217)^2)/6
sig
```
Thus, $\sigma^2 \approx 418.70$

This estimate is close to the values obtained when using the variance function for the values for Question 2.
</font>


## **C.**

<font size="3">

c) Compute the standard errors of the regression coefficients.


Taking these values from the lm function above:

$Brightness = 0.8514$

$Contrast = 0.9667$
</font>

## **D.**
<font size="3">

d) Predict the useful range when brightness = 80 and contrast = 75.

We can use the coefficients for Brightness and Contrast to predict Useful Range.
Given:
Brightness = 80 
Contrast = 75

We plug in Brightness into $X_1$ and Contrast into $X_2$

$$Useful Range = 224.7179 + (0.7768)(80) + (-3.2017)(75)$$

``` {r UsefulRange, include=TRUE, echo=FALSE}
224.7179 + (0.7768*80) + (-3.2017*75)
```
Thus, the value of Useful Range when Brightness is 80 and Contrast is 75 is

$$Useful Range = 46.7344$$

</font>

## **E.**
<font size="3">

e) Test for significance of regression using α=0.05. What is the P-value for this test?

Testing for significance of regression

We can use the p-value of 0.02992 from above.

Then, we can compare this p-value of 0.02992 to alpha = 0.05

$0.02992 < 0.05$

We conclude that the regression is significant and can be observed between the values.
</font>

## **F.**
<font size="3">

f) Construct a t-test on each regression coefficient. What conclusions can you draw about the variables in this model? Use α=0.05.

We form the hypothesis:

$$H_0: \beta_1 = 0$$  meaning no relationship in the regression model. Amounts to a bad predictor

$$H_1: \beta_1 > 0$$  meaning strong relationship in the regression model. Amounts to a good predictor.



Using the equation:

$$t_1 = \frac{b_1}{se(b_1)}$$

t-value of Brightness
$$t_1 = \frac{0.7768}{0.8514}=0.912$$

Then we find p-value at $\alpha=0.05$ using pnorm
```{r pvalueB, echo=FALSE}
bt <- pnorm(0.912, lower.tail=FALSE)
bt
```
Greater than $\alpha=0.05$

Because the p-value is greater than 0.05, this means that the Brightness variable is not a good predictor of the regression model.


t-value of Contrast
$$t_2 = \frac{-3.2017}{0.9667}=-3.312$$
```{r pvalueC, echo=FALSE}
d <-pnorm(-3.312)
d
```

Lesser than $\alpha=0.05$


This means that the p-value obtained from this shows that the Contrast variable is a good predictor of the regression model.

</font>